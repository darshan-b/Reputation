{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethomes/darshan/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/nethomes/darshan/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/nethomes/darshan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import researchpy as rp\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,auc,roc_curve,recall_score,precision_score,matthews_corrcoef\n",
    "# from pandas_ml import ConfusionMatrix\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "import imblearn.over_sampling as over\n",
    "from IPython.display import display,clear_output,HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train,Y_train,X_test,Y_test,feat):\n",
    "    print('\\033[1m' + 'RandomForest Classifier' + '\\033[0m')\n",
    "    rf=RandomForestClassifier(n_estimators=100,random_state=10)\n",
    "    rf.fit(X_train,Y_train)\n",
    "    return model_build(rf,X_train,Y_train,X_test,Y_test,True,feat)\n",
    "\n",
    "def model_build(model,X_train,Y_train,X_test,Y_test,tree=False,feat=None):    \n",
    "    y_pred_train=model.predict(X_train)\n",
    "    acc_train=accuracy_score(Y_train,y_pred_train)\n",
    "    print(\"Accuracy of the model for training data is:\",acc_train)\n",
    "    print(\"Confusion Matrix for training data is:\")\n",
    "    cm_train=ConfusionMatrix(Y_train,y_pred_train)\n",
    "    display(cm_train)\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    acc_test=accuracy_score(Y_test,y_pred_test)\n",
    "    print(\"Accuracy of the model for test data is:\",acc_test)\n",
    "    print(\"Confusion Matrix for test data is:\")\n",
    "    cm_test=ConfusionMatrix(Y_test,y_pred_test)\n",
    "    display(cm_test)\n",
    "    fpr, tpr, threshold = roc_curve(Y_test, y_pred_test)\n",
    "    roc_auc =auc(fpr, tpr)\n",
    "    mcc=matthews_corrcoef(Y_test,y_pred_test)\n",
    "    precision=precision_score(Y_test,y_pred_test)\n",
    "    recall=recall_score(Y_test,y_pred_test)\n",
    "#     if tree==True:\n",
    "#         feat_impt_plot(model.feature_importances_,feat)\n",
    "#         return model,cm_train,cm_test,acc_train,acc_test,roc_auc,model.feature_importances_,mcc,precision,recall\n",
    "    return model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,precision,recall\n",
    "\n",
    "### Function to plot Feature Importance\n",
    "def feat_impt_plot(feat_impt,y_labels,width_s=1000,height_s=1000):\n",
    "    \n",
    "    m=pd.DataFrame(y_labels,feat_impt).reset_index()\n",
    "    m.columns=['Feature_Importance','Features']\n",
    "    m.sort_values(by='Feature_Importance',inplace=True,ascending=False)\n",
    "    m['Features']=m['Features'].str.replace(\"dom_function_\",\"\")\n",
    "    m['Features']=m['Features'].str.replace(\"js_function_\",\"\")\n",
    "    m['Features']=m['Features'].apply(lambda x: str(x).lstrip('.'))\n",
    "    m['Features']=m['Features'].str.replace(\"(\",\"\")\n",
    "    \n",
    "    data = [go.Bar(x=m.Feature_Importance.values,y=m.Features.values,text=np.round(m.Feature_Importance,4),\n",
    "            textposition = 'outside',\n",
    "            marker=dict(\n",
    "                color='rgb(158,202,225)',\n",
    "                line=dict(\n",
    "                    color='rgb(8,48,107)',\n",
    "                    width=1.5),\n",
    "            ),\n",
    "            opacity=0.6,\n",
    "            orientation='h'\n",
    "        )]\n",
    "    layout = go.Layout(autosize=False,\n",
    "    width=width_s,\n",
    "    height=height_s,\n",
    "    xaxis=dict(title='Feature Importances',\n",
    "        tickfont=dict(\n",
    "            size=12,\n",
    "            color='black'\n",
    "        )),\n",
    "    yaxis=dict(automargin=True))\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../../Data/df_training_prev.csv',index_col='domain')\n",
    "\n",
    "df_mal=pd.read_csv('../../Data/Malicious_domains.csv')\n",
    "mal_domains=df_mal.queried_domain.values.tolist()\n",
    "\n",
    "df_test=pd.read_csv('../../Data/df_fin_prev.csv',index_col='domain')\n",
    "df_test.reset_index(inplace=True)\n",
    "df_test['Target']=df_test['domain'].apply(lambda x: 1 if x in mal_domains else 0)\n",
    "df_test.set_index(['domain'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev=pd.concat([df_test,df_train],axis=0,sort=False)\n",
    "df_prev=df_prev.sample(frac=1,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df=[]\n",
    "for col in df_prev.columns:\n",
    "    if col!='Target':\n",
    "        corr_df.append((df_prev[col].corr(df_prev['Target']),col))\n",
    "        \n",
    "corr_df=pd.DataFrame(corr_df)\n",
    "corr_df.columns=['Correlation_Value','Columns']\n",
    "corr_df['Correlation_Value']=corr_df['Correlation_Value'].apply(lambda x: np.absolute(x))\n",
    "corr_df.sort_values(by='Correlation_Value',inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation_Value</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.345751</td>\n",
       "      <td>url_char_-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.051610</td>\n",
       "      <td>http_header_content-language_text/html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.047706</td>\n",
       "      <td>url_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.040622</td>\n",
       "      <td>url_char_w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.038754</td>\n",
       "      <td>link_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.035611</td>\n",
       "      <td>url_extensions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.032799</td>\n",
       "      <td>http_header_content-encoding_gzip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.032450</td>\n",
       "      <td>script_type_text/javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.031223</td>\n",
       "      <td>link_href_out_of_domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.028537</td>\n",
       "      <td>url_extension_.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.028365</td>\n",
       "      <td>url_char_u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.027592</td>\n",
       "      <td>url_char_.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.027064</td>\n",
       "      <td>script_src_out_of_domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.022434</td>\n",
       "      <td>url_char_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.022278</td>\n",
       "      <td>http_header_cache-control_set_max-age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.020367</td>\n",
       "      <td>url_words_with_length_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.020208</td>\n",
       "      <td>style_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.020110</td>\n",
       "      <td>url_char_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.019220</td>\n",
       "      <td>meta_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018483</td>\n",
       "      <td>div_count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Correlation_Value                                 Columns\n",
       "61           0.345751                              url_char_-\n",
       "57           0.051610  http_header_content-language_text/html\n",
       "92           0.047706                              url_length\n",
       "84           0.040622                              url_char_w\n",
       "35           0.038754                              link_count\n",
       "91           0.035611                          url_extensions\n",
       "56           0.032799       http_header_content-encoding_gzip\n",
       "41           0.032450             script_type_text/javascript\n",
       "36           0.031223                 link_href_out_of_domain\n",
       "88           0.028537                      url_extension_.com\n",
       "82           0.028365                              url_char_u\n",
       "62           0.027592                              url_char_.\n",
       "40           0.027064                script_src_out_of_domain\n",
       "85           0.022434                              url_char_x\n",
       "50           0.022278   http_header_cache-control_set_max-age\n",
       "94           0.020367                 url_words_with_length_4\n",
       "44           0.020208                             style_count\n",
       "63           0.020110                              url_char_a\n",
       "37           0.019220                              meta_count\n",
       "5            0.018483                               div_count"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 20% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.999920589543231\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      180330     1   180331\n",
       "True           14  8547     8561\n",
       "__all__    180344  8548   188892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9578556586418201\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      720976   623   721599\n",
       "True        31220  2751    33971\n",
       "__all__    752196  3374   755570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.24899540812403015\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.2),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.2):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 30% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9998729432691696\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      270540      3   270543\n",
       "True           33  12762    12795\n",
       "__all__    270573  12765   283338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9579503996224611\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      630829   558   631387\n",
       "True        27242  2495    29737\n",
       "__all__    658071  3053   661124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.25378806130001613\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.3),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.3):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 40% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9998517671473647\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      360800      8   360808\n",
       "True           48  16928    16976\n",
       "__all__    360848  16936   377784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9580908381832364\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      540583   539   541122\n",
       "True        23210  2346    25556\n",
       "__all__    563793  2885   566678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.2647635865835293\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.4),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.4):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 50% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9998221209535164\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      451060     10   451070\n",
       "True           74  21087    21161\n",
       "__all__    451134  21097   472231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9579231350758421\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      450379   481   450860\n",
       "True        19389  1982    21371\n",
       "__all__    469768  2463   472231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.26455340746779377\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.5),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.5):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 60% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.999798827197857\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      541155     16   541171\n",
       "True           98  25408    25506\n",
       "__all__    541253  25424   566677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9582381513294599\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      360310   449   360759\n",
       "True        15328  1698    17026\n",
       "__all__    375638  2147   377785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.2717910860314553\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.6),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.6):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 70% of Combined Dataset1 and Dataset2 used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9997746259016854\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      631322     20   631342\n",
       "True          129  29652    29781\n",
       "__all__    631451  29672   661123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.958279657936253\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False  True  __all__\n",
       "Actual                          \n",
       "False      270256   332   270588\n",
       "True        11489  1262    12751\n",
       "__all__    281745  1594   283339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.27092660737062685\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.7),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.7):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(scaled_X_train,train_Y,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 20% of Combined Dataset1 and Dataset2 used. \n",
    "#### Oversampling ratio 1:1. Technique - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9999695005295817\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False    True  __all__\n",
       "Actual                            \n",
       "False      180328       3   180331\n",
       "True            8  180323   180331\n",
       "__all__    180336  180326   360662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9563415699405746\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      716912   4687   721599\n",
       "True        28300   5671    33971\n",
       "__all__    745212  10358   755570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.28591712980552103\n"
     ]
    }
   ],
   "source": [
    "columns=df_prev.columns.tolist()\n",
    "train=df_prev.iloc[:int(df_prev.shape[0]*0.2),:]\n",
    "train_X=train.iloc[:,train.columns!='Target'].values\n",
    "train_Y=train.Target.values\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(train_X)\n",
    "\n",
    "test=df_prev.iloc[int(df_prev.shape[0]*0.2):,:]\n",
    "test_X=test.iloc[:,test.columns!='Target'].values\n",
    "test_Y=test.Target.values\n",
    "scaled_X_test=scaler.transform(test_X)\n",
    "columns.remove('Target')\n",
    "\n",
    "train.Target.value_counts()\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = {1:180331})\n",
    "X_train, Y_train = sm.fit_sample(scaled_X_train,train_Y)\n",
    "\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(X_train,Y_train,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - 20% of Combined Dataset1 and Dataset2 used. \n",
    "#### Oversampling ratio 1:1. Technique - ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandomForest Classifier\u001b[0m\n",
      "Accuracy of the model for training data is: 0.9999695241894819\n",
      "Confusion Matrix for training data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False    True  __all__\n",
       "Actual                            \n",
       "False      180327       4   180331\n",
       "True            7  180604   180611\n",
       "__all__    180334  180608   360942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for test data is: 0.9556348187461122\n",
      "Confusion Matrix for test data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted   False   True  __all__\n",
       "Actual                           \n",
       "False      715758   5841   721599\n",
       "True        27680   6291    33971\n",
       "__all__    743438  12132   755570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.2919540852150978\n"
     ]
    }
   ],
   "source": [
    "sm = ADASYN(random_state=12, ratio = {1:180331},n_neighbors=10,n_jobs=-1)\n",
    "X_train, Y_train = sm.fit_sample(scaled_X_train,train_Y)\n",
    "\n",
    "model,cm_train,cm_test,acc_train,acc_test,roc_auc,mcc,prec,rec=RandomForest(X_train,Y_train,scaled_X_test,test_Y,columns)\n",
    "print(\"MCC:\",mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "To toggle code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Original Creator : Darshan Bhansali\n",
    "### HTML code to hide the input cells \n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "To toggle code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
