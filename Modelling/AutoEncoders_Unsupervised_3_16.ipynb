{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,clear_output,HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, matthews_corrcoef,\\\n",
    "                            precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import featuretools as ft\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of HTML dataset: (43491, 1461)\n",
      "Shape of JS,DOM dataset: (43294, 401)\n",
      "Shape of HTTP dataset: (45856, 672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethomes/darshan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (76,77,229,230,231,232,233,234,235,236,237,238,239,240,241,242,244,245,246,247,248,249,250,251,252,253,254,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of URL dataset: (46771, 4194)\n",
      "Shape of combined dataset: (39183, 6726)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    34742\n",
       "1     4441\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read HTML \n",
    "df_html=pd.read_csv('../html/HTML.csv',index_col='domain')\n",
    "df_html.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "cookie=[col for col in df_html.columns if 'number' in col]\n",
    "df_html.drop(cookie,axis=1,inplace=True)\n",
    "print(\"Shape of HTML dataset:\",df_html.shape)\n",
    "df_html.Target=df_html.Target.apply(lambda x: 1 if x=='Malicious' else 0)\n",
    "count_columns=[col for col in df_html.columns if col.endswith('count')]\n",
    "df_html['total_count']=df_html[count_columns].sum(axis=1)\n",
    "\n",
    "href_columns=[col for col in df_html.columns if (('href_absolute' in col) | ('href_relative' in col) | ('href_page' in col))  ]\n",
    "df_html['total_href']=df_html[href_columns].sum(axis=1)\n",
    "\n",
    "total_img_src=[col for col in df_html.columns if 'img_src_' in col]\n",
    "df_html['total_img_src']=df_html[total_img_src].sum(axis=1)\n",
    "\n",
    "\n",
    "### Read JS \n",
    "df_js=pd.read_csv('Javascript.csv',low_memory=False,index_col='domain')\n",
    "cookie=[col for col in df_js.columns if 'number' in col]\n",
    "df_js.drop(cookie,axis=1,inplace=True)\n",
    "df_js.rename(columns={'Malicious':'Target'},inplace=True)\n",
    "print(\"Shape of JS,DOM dataset:\",df_js.shape)\n",
    "df_js.Target=df_js.Target.apply(lambda x: 1 if x=='Malicious' else 0)\n",
    "\n",
    "\n",
    "### Read HTTP\n",
    "df_http=pd.read_csv('HTTP.csv')\n",
    "df_http.rename(columns={'Malicious':'Target'},inplace=True)\n",
    "df_http.fillna(value=0,inplace=True)\n",
    "cookies=[columns for columns in df_http.columns if 'number' in columns]\n",
    "df_http.drop(cookies,axis=1,inplace=True)\n",
    "df_http=df_http[df_http['domain']!=0]\n",
    "df_http.sort_values(by='Target',inplace=True,ascending=False)\n",
    "df_http.drop_duplicates(['domain'], keep='first',inplace=True)\n",
    "df_http=df_http.sample(frac=1,random_state=0)\n",
    "df_http.set_index(['domain'],drop=True,inplace=True)\n",
    "print(\"Shape of HTTP dataset:\",df_http.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Read URL\n",
    "df_url=pd.read_csv('URL.csv')\n",
    "df_url.fillna(value=0,inplace=True)\n",
    "cookies=[columns for columns in df_url.columns if 'number' in columns]\n",
    "df_url.drop(cookies,axis=1,inplace=True)\n",
    "df_url.drop(['url_host','url_ip'],axis=1,inplace=True)\n",
    "df_url=df_url[df_url['domain']!=0]\n",
    "df_url.sort_values(by='Target',inplace=True,ascending=False)\n",
    "df_url.drop_duplicates(['domain'], keep='first',inplace=True)\n",
    "df_url=df_url.sample(frac=1,random_state=0)\n",
    "print(\"Shape of URL dataset:\",df_url.shape)\n",
    "df_url.set_index('domain',inplace=True,drop=True)\n",
    "\n",
    "df=pd.concat([df_js,df_html,df_http,df_url],axis=1,join='inner')\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df['Target_z']=df[['Target','Target','Target','Target']].apply(max,axis=1)\n",
    "df.drop(['Target','Target','Target','Target'],axis=1,inplace=True)\n",
    "print(\"Shape of combined dataset:\",df.shape)\n",
    "df.rename(columns={'Target_z':'Target'},inplace=True)\n",
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features being used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['js_function_.push(',\n",
       " 'a_count',\n",
       " 'a_href_http',\n",
       " 'a_href_https',\n",
       " 'a_href_out_of_domain',\n",
       " 'a_href_relative',\n",
       " 'center_count',\n",
       " 'form_action_http',\n",
       " 'iframe_src_.html',\n",
       " 'img_src_http',\n",
       " 'link_href_out_of_domain',\n",
       " 'link_type_text/css',\n",
       " 'meta_count',\n",
       " 'p_count',\n",
       " 'script_async_true',\n",
       " 'total_count',\n",
       " 'total_href',\n",
       " 'http_header_cache-control_set_max-age',\n",
       " 'http_header_content-encoding_gzip',\n",
       " 'http_header_server_apache',\n",
       " 'http_header_transfer-encoding_chunked',\n",
       " 'http_header_vary_user-agent',\n",
       " 'http_header_via_1.1',\n",
       " 'url_char_.',\n",
       " 'url_char_f',\n",
       " 'url_char_i',\n",
       " 'url_char_l',\n",
       " 'url_char_p',\n",
       " 'url_char_w',\n",
       " 'url_char_y',\n",
       " 'url_char_z',\n",
       " 'url_extension_.com',\n",
       " 'url_extensions',\n",
       " 'url_length',\n",
       " 'Target']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns=['js_function_.push(',\n",
    " 'a_count',\n",
    " 'a_href_http',\n",
    " 'a_href_https',\n",
    " 'a_href_out_of_domain',\n",
    " 'a_href_relative',\n",
    " 'center_count',\n",
    " 'form_action_http',\n",
    " 'iframe_src_.html',\n",
    " 'img_src_http',\n",
    " 'link_href_out_of_domain',\n",
    " 'link_type_text/css',\n",
    " 'meta_count',\n",
    " 'p_count',\n",
    " 'script_async_true',\n",
    " 'total_count',\n",
    " 'total_href',\n",
    " 'http_header_cache-control_set_max-age',\n",
    " 'http_header_content-encoding_gzip',\n",
    " 'http_header_server_apache',\n",
    " 'http_header_transfer-encoding_chunked',\n",
    " 'http_header_vary_user-agent',\n",
    " 'http_header_via_1.1',\n",
    " 'url_char_.',\n",
    " 'url_char_f',\n",
    " 'url_char_i',\n",
    " 'url_char_l',\n",
    " 'url_char_p',\n",
    " 'url_char_w',\n",
    " 'url_char_y',\n",
    " 'url_char_z',\n",
    " 'url_extension_.com',\n",
    " 'url_extensions',\n",
    " 'url_length',\n",
    " 'Target']\n",
    "\n",
    "df['url_extension_endswith_.com']=df['url_extension_endswith_.com'].apply(lambda x: 1 if x==True else x)\n",
    "df['url_extension_endswith_.com']=df['url_extension_endswith_.com'].astype(int)\n",
    "print(\"features being used\")\n",
    "display(columns)\n",
    "df_sel=df[columns].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. No - Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60% for training, 20% for validation, 20% for testing  \n",
    "#### Split into Training and test set first. Split Training into training and validation. \n",
    "### We then remove malicious domains from training set and only include the non-malicious domains in the train-set. Thus, we cant perform over-sampling or undersampling\n",
    "#### Standardize training and then scaled validation and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df_sel, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=0)\n",
    "X_train = X_train[X_train.Target == 0]\n",
    "X_train = X_train.drop(['Target'], axis=1) \n",
    "sc = StandardScaler()\n",
    "scaled_X_train = sc.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_val = X_val.drop(['Target'],axis=1)\n",
    "scaled_X_val = sc.transform(X_val)\n",
    "\n",
    "y_test = X_test['Target']\n",
    "X_test = X_test.drop(['Target'], axis=1)\n",
    "scaled_X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. L1 regularization of 10e-5\n",
    "#### b. 4 encoding layers with 20,10,5 and 35 neurons respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = scaled_X_train.shape[1]\n",
    "encoding_dim = 20\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200 epochs, batch_size=64, optimizer = ADAM , loss = mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22261 samples, validate on 6270 samples\n",
      "Epoch 1/500\n",
      "22261/22261 [==============================] - 1s 26us/step - loss: 0.9366 - binary_accuracy: 0.0000e+00 - val_loss: 1.1182 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.7965 - binary_accuracy: 0.0000e+00 - val_loss: 0.9721 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.7029 - binary_accuracy: 0.0000e+00 - val_loss: 0.8701 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.6399 - binary_accuracy: 0.0000e+00 - val_loss: 0.8177 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.6029 - binary_accuracy: 0.0000e+00 - val_loss: 0.7863 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.5771 - binary_accuracy: 0.0000e+00 - val_loss: 0.7606 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5608 - binary_accuracy: 0.0000e+00 - val_loss: 0.7457 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5503 - binary_accuracy: 0.0000e+00 - val_loss: 0.7342 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5422 - binary_accuracy: 0.0000e+00 - val_loss: 0.7244 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5359 - binary_accuracy: 0.0000e+00 - val_loss: 0.7176 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5302 - binary_accuracy: 0.0000e+00 - val_loss: 0.7110 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5250 - binary_accuracy: 0.0000e+00 - val_loss: 0.7059 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5200 - binary_accuracy: 0.0000e+00 - val_loss: 0.7016 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5152 - binary_accuracy: 0.0000e+00 - val_loss: 0.6981 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5111 - binary_accuracy: 0.0000e+00 - val_loss: 0.6937 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5077 - binary_accuracy: 0.0000e+00 - val_loss: 0.6879 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5044 - binary_accuracy: 0.0000e+00 - val_loss: 0.6832 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.5015 - binary_accuracy: 0.0000e+00 - val_loss: 0.6790 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4985 - binary_accuracy: 0.0000e+00 - val_loss: 0.6745 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4960 - binary_accuracy: 0.0000e+00 - val_loss: 0.6705 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4935 - binary_accuracy: 0.0000e+00 - val_loss: 0.6678 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4917 - binary_accuracy: 0.0000e+00 - val_loss: 0.6641 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4896 - binary_accuracy: 0.0000e+00 - val_loss: 0.6590 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4872 - binary_accuracy: 0.0000e+00 - val_loss: 0.6533 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4854 - binary_accuracy: 0.0000e+00 - val_loss: 0.6495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4834 - binary_accuracy: 0.0000e+00 - val_loss: 0.6469 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4820 - binary_accuracy: 0.0000e+00 - val_loss: 0.6434 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4803 - binary_accuracy: 0.0000e+00 - val_loss: 0.6422 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4793 - binary_accuracy: 0.0000e+00 - val_loss: 0.6394 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4776 - binary_accuracy: 0.0000e+00 - val_loss: 0.6373 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4761 - binary_accuracy: 0.0000e+00 - val_loss: 0.6346 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4710 - binary_accuracy: 0.0000e+00 - val_loss: 0.5936 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4609 - binary_accuracy: 0.0000e+00 - val_loss: 0.5614 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4550 - binary_accuracy: 0.0000e+00 - val_loss: 0.5447 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4522 - binary_accuracy: 0.0000e+00 - val_loss: 0.5402 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4500 - binary_accuracy: 0.0000e+00 - val_loss: 0.5365 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4488 - binary_accuracy: 0.0000e+00 - val_loss: 0.5347 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4473 - binary_accuracy: 0.0000e+00 - val_loss: 0.5326 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "22261/22261 [==============================] - 0s 18us/step - loss: 0.4464 - binary_accuracy: 0.0000e+00 - val_loss: 0.5310 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.4454 - binary_accuracy: 0.0000e+00 - val_loss: 0.5304 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "22261/22261 [==============================] - 0s 18us/step - loss: 0.4450 - binary_accuracy: 0.0000e+00 - val_loss: 0.5293 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.4435 - binary_accuracy: 0.0000e+00 - val_loss: 0.5286 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.4432 - binary_accuracy: 0.0000e+00 - val_loss: 0.5274 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.4422 - binary_accuracy: 0.0000e+00 - val_loss: 0.5260 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4410 - binary_accuracy: 0.0000e+00 - val_loss: 0.5247 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4403 - binary_accuracy: 0.0000e+00 - val_loss: 0.5240 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4388 - binary_accuracy: 0.0000e+00 - val_loss: 0.5218 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4383 - binary_accuracy: 0.0000e+00 - val_loss: 0.5206 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4370 - binary_accuracy: 0.0000e+00 - val_loss: 0.5180 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4362 - binary_accuracy: 0.0000e+00 - val_loss: 0.5173 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4354 - binary_accuracy: 0.0000e+00 - val_loss: 0.5149 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4346 - binary_accuracy: 0.0000e+00 - val_loss: 0.5133 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4339 - binary_accuracy: 0.0000e+00 - val_loss: 0.5131 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4327 - binary_accuracy: 0.0000e+00 - val_loss: 0.5110 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4317 - binary_accuracy: 0.0000e+00 - val_loss: 0.5095 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4312 - binary_accuracy: 0.0000e+00 - val_loss: 0.5088 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4305 - binary_accuracy: 0.0000e+00 - val_loss: 0.5066 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4298 - binary_accuracy: 0.0000e+00 - val_loss: 0.5060 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4288 - binary_accuracy: 0.0000e+00 - val_loss: 0.5032 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4283 - binary_accuracy: 0.0000e+00 - val_loss: 0.5004 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4275 - binary_accuracy: 0.0000e+00 - val_loss: 0.5000 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4269 - binary_accuracy: 0.0000e+00 - val_loss: 0.4949 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4260 - binary_accuracy: 0.0000e+00 - val_loss: 0.4832 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4247 - binary_accuracy: 0.0000e+00 - val_loss: 0.4816 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4239 - binary_accuracy: 0.0000e+00 - val_loss: 0.4828 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4233 - binary_accuracy: 0.0000e+00 - val_loss: 0.4812 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4226 - binary_accuracy: 0.0000e+00 - val_loss: 0.4788 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4216 - binary_accuracy: 0.0000e+00 - val_loss: 0.4777 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4216 - binary_accuracy: 0.0000e+00 - val_loss: 0.4766 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4211 - binary_accuracy: 0.0000e+00 - val_loss: 0.4762 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4215 - binary_accuracy: 0.0000e+00 - val_loss: 0.4791 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4195 - binary_accuracy: 0.0000e+00 - val_loss: 0.4798 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4173 - binary_accuracy: 0.0000e+00 - val_loss: 0.4852 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4122 - binary_accuracy: 0.0000e+00 - val_loss: 0.4804 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4082 - binary_accuracy: 0.0000e+00 - val_loss: 0.4748 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4045 - binary_accuracy: 0.0000e+00 - val_loss: 0.4752 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4034 - binary_accuracy: 0.0000e+00 - val_loss: 0.4742 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4026 - binary_accuracy: 0.0000e+00 - val_loss: 0.4734 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4026 - binary_accuracy: 0.0000e+00 - val_loss: 0.4702 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4017 - binary_accuracy: 0.0000e+00 - val_loss: 0.4713 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4017 - binary_accuracy: 0.0000e+00 - val_loss: 0.4690 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4013 - binary_accuracy: 0.0000e+00 - val_loss: 0.4685 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.4007 - binary_accuracy: 0.0000e+00 - val_loss: 0.4688 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4010 - binary_accuracy: 0.0000e+00 - val_loss: 0.4688 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4007 - binary_accuracy: 0.0000e+00 - val_loss: 0.4683 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4002 - binary_accuracy: 0.0000e+00 - val_loss: 0.4677 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4004 - binary_accuracy: 0.0000e+00 - val_loss: 0.4686 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4005 - binary_accuracy: 0.0000e+00 - val_loss: 0.4690 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.4003 - binary_accuracy: 0.0000e+00 - val_loss: 0.4678 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3990 - binary_accuracy: 0.0000e+00 - val_loss: 0.4680 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3991 - binary_accuracy: 0.0000e+00 - val_loss: 0.4695 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3993 - binary_accuracy: 0.0000e+00 - val_loss: 0.4690 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3982 - binary_accuracy: 0.0000e+00 - val_loss: 0.4713 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3986 - binary_accuracy: 0.0000e+00 - val_loss: 0.4713 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3978 - binary_accuracy: 0.0000e+00 - val_loss: 0.4735 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3975 - binary_accuracy: 0.0000e+00 - val_loss: 0.4705 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3978 - binary_accuracy: 0.0000e+00 - val_loss: 0.4717 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3975 - binary_accuracy: 0.0000e+00 - val_loss: 0.4706 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3975 - binary_accuracy: 0.0000e+00 - val_loss: 0.4690 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3972 - binary_accuracy: 0.0000e+00 - val_loss: 0.4725 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3983 - binary_accuracy: 0.0000e+00 - val_loss: 0.4688 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3964 - binary_accuracy: 0.0000e+00 - val_loss: 0.4713 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3972 - binary_accuracy: 0.0000e+00 - val_loss: 0.4669 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3965 - binary_accuracy: 0.0000e+00 - val_loss: 0.4700 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3965 - binary_accuracy: 0.0000e+00 - val_loss: 0.4690 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3960 - binary_accuracy: 0.0000e+00 - val_loss: 0.4692 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3957 - binary_accuracy: 0.0000e+00 - val_loss: 0.4665 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3956 - binary_accuracy: 0.0000e+00 - val_loss: 0.4684 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3961 - binary_accuracy: 0.0000e+00 - val_loss: 0.4668 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3950 - binary_accuracy: 0.0000e+00 - val_loss: 0.4651 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3946 - binary_accuracy: 0.0000e+00 - val_loss: 0.4638 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3954 - binary_accuracy: 0.0000e+00 - val_loss: 0.4615 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3946 - binary_accuracy: 0.0000e+00 - val_loss: 0.4620 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3949 - binary_accuracy: 0.0000e+00 - val_loss: 0.4602 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3936 - binary_accuracy: 0.0000e+00 - val_loss: 0.4599 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3942 - binary_accuracy: 0.0000e+00 - val_loss: 0.4583 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3945 - binary_accuracy: 0.0000e+00 - val_loss: 0.4610 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3939 - binary_accuracy: 0.0000e+00 - val_loss: 0.4580 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.3936 - binary_accuracy: 0.0000e+00 - val_loss: 0.4577 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3930 - binary_accuracy: 0.0000e+00 - val_loss: 0.4596 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3930 - binary_accuracy: 0.0000e+00 - val_loss: 0.4573 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3929 - binary_accuracy: 0.0000e+00 - val_loss: 0.4581 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3933 - binary_accuracy: 0.0000e+00 - val_loss: 0.4562 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3931 - binary_accuracy: 0.0000e+00 - val_loss: 0.4585 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3926 - binary_accuracy: 0.0000e+00 - val_loss: 0.4574 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3927 - binary_accuracy: 0.0000e+00 - val_loss: 0.4568 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3928 - binary_accuracy: 0.0000e+00 - val_loss: 0.4574 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3921 - binary_accuracy: 0.0000e+00 - val_loss: 0.4564 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3930 - binary_accuracy: 0.0000e+00 - val_loss: 0.4565 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3921 - binary_accuracy: 0.0000e+00 - val_loss: 0.4561 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3920 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3924 - binary_accuracy: 0.0000e+00 - val_loss: 0.4553 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3926 - binary_accuracy: 0.0000e+00 - val_loss: 0.4555 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3918 - binary_accuracy: 0.0000e+00 - val_loss: 0.4545 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3922 - binary_accuracy: 0.0000e+00 - val_loss: 0.4553 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3923 - binary_accuracy: 0.0000e+00 - val_loss: 0.4561 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3920 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3918 - binary_accuracy: 0.0000e+00 - val_loss: 0.4547 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3925 - binary_accuracy: 0.0000e+00 - val_loss: 0.4549 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3914 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3909 - binary_accuracy: 0.0000e+00 - val_loss: 0.4545 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3915 - binary_accuracy: 0.0000e+00 - val_loss: 0.4559 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3915 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3910 - binary_accuracy: 0.0000e+00 - val_loss: 0.4549 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3914 - binary_accuracy: 0.0000e+00 - val_loss: 0.4560 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3927 - binary_accuracy: 0.0000e+00 - val_loss: 0.4544 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3919 - binary_accuracy: 0.0000e+00 - val_loss: 0.4558 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3905 - binary_accuracy: 0.0000e+00 - val_loss: 0.4537 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3914 - binary_accuracy: 0.0000e+00 - val_loss: 0.4542 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3905 - binary_accuracy: 0.0000e+00 - val_loss: 0.4541 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3911 - binary_accuracy: 0.0000e+00 - val_loss: 0.4542 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3925 - binary_accuracy: 0.0000e+00 - val_loss: 0.4567 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3913 - binary_accuracy: 0.0000e+00 - val_loss: 0.4553 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3904 - binary_accuracy: 0.0000e+00 - val_loss: 0.4555 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3910 - binary_accuracy: 0.0000e+00 - val_loss: 0.4542 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3921 - binary_accuracy: 0.0000e+00 - val_loss: 0.4565 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3919 - binary_accuracy: 0.0000e+00 - val_loss: 0.4563 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.3911 - binary_accuracy: 0.0000e+00 - val_loss: 0.4547 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3912 - binary_accuracy: 0.0000e+00 - val_loss: 0.4547 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3915 - binary_accuracy: 0.0000e+00 - val_loss: 0.4527 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3903 - binary_accuracy: 0.0000e+00 - val_loss: 0.4544 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3906 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3925 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3906 - binary_accuracy: 0.0000e+00 - val_loss: 0.4542 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3912 - binary_accuracy: 0.0000e+00 - val_loss: 0.4556 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3924 - binary_accuracy: 0.0000e+00 - val_loss: 0.4551 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3910 - binary_accuracy: 0.0000e+00 - val_loss: 0.4544 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3900 - binary_accuracy: 0.0000e+00 - val_loss: 0.4535 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3909 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3901 - binary_accuracy: 0.0000e+00 - val_loss: 0.4540 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3901 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3903 - binary_accuracy: 0.0000e+00 - val_loss: 0.4546 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3912 - binary_accuracy: 0.0000e+00 - val_loss: 0.4552 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3917 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3904 - binary_accuracy: 0.0000e+00 - val_loss: 0.4557 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3905 - binary_accuracy: 0.0000e+00 - val_loss: 0.4574 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3908 - binary_accuracy: 0.0000e+00 - val_loss: 0.4546 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3899 - binary_accuracy: 0.0000e+00 - val_loss: 0.4531 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3900 - binary_accuracy: 0.0000e+00 - val_loss: 0.4539 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3898 - binary_accuracy: 0.0000e+00 - val_loss: 0.4540 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3898 - binary_accuracy: 0.0000e+00 - val_loss: 0.4537 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3901 - binary_accuracy: 0.0000e+00 - val_loss: 0.4534 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3906 - binary_accuracy: 0.0000e+00 - val_loss: 0.4558 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3913 - binary_accuracy: 0.0000e+00 - val_loss: 0.4555 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3913 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3900 - binary_accuracy: 0.0000e+00 - val_loss: 0.4567 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3905 - binary_accuracy: 0.0000e+00 - val_loss: 0.4533 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3901 - binary_accuracy: 0.0000e+00 - val_loss: 0.4518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3904 - binary_accuracy: 0.0000e+00 - val_loss: 0.4564 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3902 - binary_accuracy: 0.0000e+00 - val_loss: 0.4558 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3897 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4537 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3903 - binary_accuracy: 0.0000e+00 - val_loss: 0.4525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3896 - binary_accuracy: 0.0000e+00 - val_loss: 0.4545 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4527 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4532 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3902 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3896 - binary_accuracy: 0.0000e+00 - val_loss: 0.4531 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3904 - binary_accuracy: 0.0000e+00 - val_loss: 0.4557 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4539 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3904 - binary_accuracy: 0.0000e+00 - val_loss: 0.4546 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3903 - binary_accuracy: 0.0000e+00 - val_loss: 0.4564 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3898 - binary_accuracy: 0.0000e+00 - val_loss: 0.4527 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3900 - binary_accuracy: 0.0000e+00 - val_loss: 0.4542 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4532 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3893 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3894 - binary_accuracy: 0.0000e+00 - val_loss: 0.4543 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4532 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3897 - binary_accuracy: 0.0000e+00 - val_loss: 0.4526 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4538 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3908 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3893 - binary_accuracy: 0.0000e+00 - val_loss: 0.4518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4527 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4524 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4536 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3899 - binary_accuracy: 0.0000e+00 - val_loss: 0.4532 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3893 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3889 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3893 - binary_accuracy: 0.0000e+00 - val_loss: 0.4518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3886 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3886 - binary_accuracy: 0.0000e+00 - val_loss: 0.4530 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3889 - binary_accuracy: 0.0000e+00 - val_loss: 0.4525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4524 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3892 - binary_accuracy: 0.0000e+00 - val_loss: 0.4526 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3888 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3886 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3898 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3911 - binary_accuracy: 0.0000e+00 - val_loss: 0.4555 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4566 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3902 - binary_accuracy: 0.0000e+00 - val_loss: 0.4515 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3882 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3881 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3896 - binary_accuracy: 0.0000e+00 - val_loss: 0.4529 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3898 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4534 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3895 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3886 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4537 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3877 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3894 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4544 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3882 - binary_accuracy: 0.0000e+00 - val_loss: 0.4534 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4605 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3893 - binary_accuracy: 0.0000e+00 - val_loss: 0.4522 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4531 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3881 - binary_accuracy: 0.0000e+00 - val_loss: 0.4529 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3883 - binary_accuracy: 0.0000e+00 - val_loss: 0.4591 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3881 - binary_accuracy: 0.0000e+00 - val_loss: 0.4583 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3888 - binary_accuracy: 0.0000e+00 - val_loss: 0.4563 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4527 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3889 - binary_accuracy: 0.0000e+00 - val_loss: 0.4609 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3894 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3883 - binary_accuracy: 0.0000e+00 - val_loss: 0.4531 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3891 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4533 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3878 - binary_accuracy: 0.0000e+00 - val_loss: 0.4540 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4574 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4546 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4578 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3882 - binary_accuracy: 0.0000e+00 - val_loss: 0.4539 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3877 - binary_accuracy: 0.0000e+00 - val_loss: 0.4515 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4534 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3890 - binary_accuracy: 0.0000e+00 - val_loss: 0.4535 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3883 - binary_accuracy: 0.0000e+00 - val_loss: 0.4526 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4529 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3874 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4538 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3889 - binary_accuracy: 0.0000e+00 - val_loss: 0.4580 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3877 - binary_accuracy: 0.0000e+00 - val_loss: 0.4516 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3864 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3882 - binary_accuracy: 0.0000e+00 - val_loss: 0.4522 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3878 - binary_accuracy: 0.0000e+00 - val_loss: 0.4548 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3874 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3871 - binary_accuracy: 0.0000e+00 - val_loss: 0.4554 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4526 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4511 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3883 - binary_accuracy: 0.0000e+00 - val_loss: 0.4537 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4531 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4516 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3871 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3870 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4524 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4515 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4522 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4528 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3885 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4508 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4503 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4530 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3883 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4510 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3877 - binary_accuracy: 0.0000e+00 - val_loss: 0.4503 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3860 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4508 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3864 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4530 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4510 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3876 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4504 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4515 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3860 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4511 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4508 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3900 - binary_accuracy: 0.0000e+00 - val_loss: 0.4525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4504 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4488 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3860 - binary_accuracy: 0.0000e+00 - val_loss: 0.4512 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4487 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4489 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4487 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3860 - binary_accuracy: 0.0000e+00 - val_loss: 0.4490 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4501 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4492 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3870 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4485 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4512 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4503 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3884 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4487 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4489 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4488 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3853 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3869 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4489 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3860 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3874 - binary_accuracy: 0.0000e+00 - val_loss: 0.4513 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3870 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3849 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4504 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3871 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4516 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3868 - binary_accuracy: 0.0000e+00 - val_loss: 0.4502 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4511 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4512 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4510 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3872 - binary_accuracy: 0.0000e+00 - val_loss: 0.4521 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3874 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3846 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3873 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4503 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4515 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3874 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3870 - binary_accuracy: 0.0000e+00 - val_loss: 0.4517 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4502 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4512 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3870 - binary_accuracy: 0.0000e+00 - val_loss: 0.4510 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4502 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4501 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3864 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3864 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3864 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4503 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3863 - binary_accuracy: 0.0000e+00 - val_loss: 0.4490 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4491 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "22261/22261 [==============================] - 0s 18us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4508 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3887 - binary_accuracy: 0.0000e+00 - val_loss: 0.4529 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3850 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4490 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3853 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3861 - binary_accuracy: 0.0000e+00 - val_loss: 0.4492 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3848 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3859 - binary_accuracy: 0.0000e+00 - val_loss: 0.4489 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3866 - binary_accuracy: 0.0000e+00 - val_loss: 0.4507 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3875 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3858 - binary_accuracy: 0.0000e+00 - val_loss: 0.4514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3853 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4481 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3865 - binary_accuracy: 0.0000e+00 - val_loss: 0.4497 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3846 - binary_accuracy: 0.0000e+00 - val_loss: 0.4484 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3888 - binary_accuracy: 0.0000e+00 - val_loss: 0.4516 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4483 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4490 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4499 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3856 - binary_accuracy: 0.0000e+00 - val_loss: 0.4498 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3855 - binary_accuracy: 0.0000e+00 - val_loss: 0.4496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3879 - binary_accuracy: 0.0000e+00 - val_loss: 0.4516 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.3853 - binary_accuracy: 0.0000e+00 - val_loss: 0.4491 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3881 - binary_accuracy: 0.0000e+00 - val_loss: 0.4508 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3867 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3851 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3847 - binary_accuracy: 0.0000e+00 - val_loss: 0.4481 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4491 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3880 - binary_accuracy: 0.0000e+00 - val_loss: 0.4509 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3862 - binary_accuracy: 0.0000e+00 - val_loss: 0.4495 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3857 - binary_accuracy: 0.0000e+00 - val_loss: 0.4493 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3854 - binary_accuracy: 0.0000e+00 - val_loss: 0.4500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.3852 - binary_accuracy: 0.0000e+00 - val_loss: 0.4492 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.3848 - binary_accuracy: 0.0000e+00 - val_loss: 0.4494 - val_binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2ea98f9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 500\n",
    "batch_size = 64\n",
    "autoencoder.compile(optimizer='adam',loss='mean_squared_error',metrics=['binary_accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"3_16_ns_model.h5\",verbose=0,save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',histogram_freq=0,write_graph=True,write_images=True)\n",
    "autoencoder.fit(scaled_X_train, scaled_X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    validation_data=(scaled_X_val, scaled_X_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(scaled_X_test)\n",
    "mse = np.mean(np.power(scaled_X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7837.000000\n",
       "mean        0.433832\n",
       "std         0.860996\n",
       "min         0.083598\n",
       "25%         0.238801\n",
       "50%         0.335168\n",
       "75%         0.461486\n",
       "max        53.159743\n",
       "Name: reconstruction_error, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.reconstruction_error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,52,1):\n",
    "#     threshold=i\n",
    "#     y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "# #     pd.crosstab(error_df.true_class.values,np.array(y_pred))\n",
    "#     print(i)\n",
    "#     print(\"MCC on test set : \" , matthews_corrcoef( error_df.true_class.values , np.array(y_pred) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.8517289779252265\n",
      "MCC on test set :  0.3258475007531144\n",
      "Precision :  0.37209302325581395\n",
      "Recall :  0.4509582863585118\n",
      "AUC :  0.6769179921001192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6275</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "row_0           \n",
       "0      6275  675\n",
       "1       487  400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in np.arange(0,1,0.01):\n",
    "#     threshold=i\n",
    "#     y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "# #     pd.crosstab(error_df.true_class.values,np.array(y_pred))\n",
    "#     print(i)\n",
    "#     print(\"MCC on test set : \" , matthews_corrcoef( error_df.true_class.values , np.array(y_pred) ) )\n",
    "# conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "threshold=0.6\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "print(\"Accuracy on test set : \", accuracy_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"MCC on test set : \" , matthews_corrcoef( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Precision : \" , precision_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Recall : \" , recall_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"AUC : \" , roc_auc_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "pd.crosstab(error_df.true_class.values,np.array(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 2278 features\n",
      "EntitySet scattered to workers in 3.801 seconds\n",
      "Elapsed: 00:07 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 11/11 chunks\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "columns.remove('Target')\n",
    "columns.append('domain')\n",
    "df_min=df[columns]\n",
    "\n",
    "es = ft.EntitySet(id = 'malicious')\n",
    "es.entity_from_dataframe(entity_id = 'data', dataframe = df_min, index = 'domain')\n",
    "\n",
    "feature_matrix_sessions, features_defs = ft.dfs(entityset=es,target_entity=\"data\",\n",
    "                                                trans_primitives = ['add','divide','multiply'],n_jobs=-1,\n",
    "                                                verbose=1,max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index(['domain'],drop=True,inplace=True)\n",
    "fs=pd.merge(feature_matrix_sessions,pd.DataFrame(df_sel.Target),left_index=True, right_index=True)\n",
    "fs.replace([np.inf],0,inplace=True)\n",
    "fs.fillna(value=0,inplace=True)\n",
    "fs=fs.reindex(df.index.values)\n",
    "X=fs.loc[:,fs.columns!='Target']\n",
    "y=fs.Target\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url_length / total_count',\n",
       " 'url_extensions / total_count',\n",
       " 'url_char_w + url_char_z',\n",
       " 'url_char_. / total_count',\n",
       " 'url_char_. + url_char_w',\n",
       " 'http_header_server_apache / total_count',\n",
       " 'http_header_server_apache + url_char_w',\n",
       " 'a_href_relative / total_href',\n",
       " 'url_extensions / url_char_z',\n",
       " 'url_extensions',\n",
       " 'url_char_z / total_count',\n",
       " 'url_char_y * url_extensions',\n",
       " 'url_char_w / total_count',\n",
       " 'url_char_w + url_extensions',\n",
       " 'url_char_w * url_length',\n",
       " 'url_char_w * url_extensions',\n",
       " 'url_char_w',\n",
       " 'url_char_p / total_count',\n",
       " 'url_char_p + url_extensions',\n",
       " 'url_char_l / total_count',\n",
       " 'url_char_i / total_count',\n",
       " 'url_char_f / total_count',\n",
       " 'url_char_f + url_extensions',\n",
       " 'url_char_f + url_char_w',\n",
       " 'url_char_. + url_extensions',\n",
       " 'url_char_. + url_char_z',\n",
       " 'url_char_. + url_char_y',\n",
       " 'url_char_. * url_char_w',\n",
       " 'url_char_.',\n",
       " 'http_header_via_1.1 + url_extensions',\n",
       " 'http_header_vary_user-agent + url_extensions',\n",
       " 'http_header_vary_user-agent + url_char_.',\n",
       " 'http_header_server_apache + url_extensions',\n",
       " 'http_header_content-encoding_gzip / url_char_.',\n",
       " 'a_href_relative / a_count',\n",
       " 'a_href_out_of_domain / total_href',\n",
       " 'a_href_https / a_count',\n",
       " 'Target']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_name=['url_length / total_count',\n",
    " 'url_extensions / total_count',\n",
    " 'url_char_w + url_char_z',\n",
    " 'url_char_. / total_count',\n",
    " 'url_char_. + url_char_w',\n",
    " 'http_header_server_apache / total_count',\n",
    " 'http_header_server_apache + url_char_w',\n",
    " 'a_href_relative / total_href',\n",
    " 'url_extensions / url_char_z',\n",
    " 'url_extensions',\n",
    " 'url_char_z / total_count',\n",
    " 'url_char_y * url_extensions',\n",
    " 'url_char_w / total_count',\n",
    " 'url_char_w + url_extensions',\n",
    " 'url_char_w * url_length',\n",
    " 'url_char_w * url_extensions',\n",
    " 'url_char_w',\n",
    " 'url_char_p / total_count',\n",
    " 'url_char_p + url_extensions',\n",
    " 'url_char_l / total_count',\n",
    " 'url_char_i / total_count',\n",
    " 'url_char_f / total_count',\n",
    " 'url_char_f + url_extensions',\n",
    " 'url_char_f + url_char_w',\n",
    " 'url_char_. + url_extensions',\n",
    " 'url_char_. + url_char_z',\n",
    " 'url_char_. + url_char_y',\n",
    " 'url_char_. * url_char_w',\n",
    " 'url_char_.',\n",
    " 'http_header_via_1.1 + url_extensions',\n",
    " 'http_header_vary_user-agent + url_extensions',\n",
    " 'http_header_vary_user-agent + url_char_.',\n",
    " 'http_header_server_apache + url_extensions',\n",
    " 'http_header_content-encoding_gzip / url_char_.',\n",
    " 'a_href_relative / a_count',\n",
    " 'a_href_out_of_domain / total_href',\n",
    " 'a_href_https / a_count','Target']\n",
    "display(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=fs.reindex(df_sel.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60% for training, 20% for validation, 20% for testing  \n",
    "#### Split into Training and test set first. Split Training into training and validation. \n",
    "### We then remove malicious domains from training set and only include the non-malicious domains in the train-set. Thus, we cant-perform over-sampling or undersampling\n",
    "#### Standardize training and then scaled validation and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(fs[feature_name], test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=0)\n",
    "X_train = X_train[X_train.Target == 0]\n",
    "X_train = X_train.drop(['Target'], axis=1) \n",
    "sc = StandardScaler()\n",
    "scaled_X_train = sc.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_val = X_val.drop(['Target'],axis=1)\n",
    "scaled_X_val = sc.transform(X_val)\n",
    "\n",
    "y_test = X_test['Target']\n",
    "X_test = X_test.drop(['Target'], axis=1)\n",
    "scaled_X_test = sc.transform(X_test)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. L1 regularization of 10e-5\n",
    "#### b. 4 encoding layers with 20,10,5 and 35 neurons respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 20\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200 epochs, batch_size=64, optimizer = SDG , loss = mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22261 samples, validate on 6270 samples\n",
      "Epoch 1/200\n",
      "22261/22261 [==============================] - 0s 19us/step - loss: 1.0507 - binary_accuracy: 0.0000e+00 - val_loss: 3.5029 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "22261/22261 [==============================] - 0s 12us/step - loss: 1.0166 - binary_accuracy: 0.0000e+00 - val_loss: 3.3191 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.9861 - binary_accuracy: 0.0000e+00 - val_loss: 3.1172 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.9600 - binary_accuracy: 0.0000e+00 - val_loss: 2.9260 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.9374 - binary_accuracy: 0.0000e+00 - val_loss: 2.7518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.9165 - binary_accuracy: 0.0000e+00 - val_loss: 2.6009 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.8961 - binary_accuracy: 0.0000e+00 - val_loss: 2.4717 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.8750 - binary_accuracy: 0.0000e+00 - val_loss: 2.3684 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.8547 - binary_accuracy: 0.0000e+00 - val_loss: 2.2942 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.8367 - binary_accuracy: 0.0000e+00 - val_loss: 2.2333 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.8195 - binary_accuracy: 0.0000e+00 - val_loss: 2.1675 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.8000 - binary_accuracy: 0.0000e+00 - val_loss: 2.0868 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.7784 - binary_accuracy: 0.0000e+00 - val_loss: 1.9956 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.7567 - binary_accuracy: 0.0000e+00 - val_loss: 1.9197 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.7375 - binary_accuracy: 0.0000e+00 - val_loss: 1.8610 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.7218 - binary_accuracy: 0.0000e+00 - val_loss: 1.8154 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.7096 - binary_accuracy: 0.0000e+00 - val_loss: 1.7802 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6999 - binary_accuracy: 0.0000e+00 - val_loss: 1.7519 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6919 - binary_accuracy: 0.0000e+00 - val_loss: 1.7281 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6849 - binary_accuracy: 0.0000e+00 - val_loss: 1.7062 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6784 - binary_accuracy: 0.0000e+00 - val_loss: 1.6860 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6725 - binary_accuracy: 0.0000e+00 - val_loss: 1.6681 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6669 - binary_accuracy: 0.0000e+00 - val_loss: 1.6524 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6617 - binary_accuracy: 0.0000e+00 - val_loss: 1.6390 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6568 - binary_accuracy: 0.0000e+00 - val_loss: 1.6291 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6520 - binary_accuracy: 0.0000e+00 - val_loss: 1.6208 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6475 - binary_accuracy: 0.0000e+00 - val_loss: 1.6148 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6430 - binary_accuracy: 0.0000e+00 - val_loss: 1.6081 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6376 - binary_accuracy: 0.0000e+00 - val_loss: 1.5997 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6328 - binary_accuracy: 0.0000e+00 - val_loss: 1.5919 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6281 - binary_accuracy: 0.0000e+00 - val_loss: 1.5820 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6233 - binary_accuracy: 0.0000e+00 - val_loss: 1.5786 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.6184 - binary_accuracy: 0.0000e+00 - val_loss: 1.5722 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6137 - binary_accuracy: 0.0000e+00 - val_loss: 1.5641 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6096 - binary_accuracy: 0.0000e+00 - val_loss: 1.5583 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6059 - binary_accuracy: 0.0000e+00 - val_loss: 1.5536 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.6026 - binary_accuracy: 0.0000e+00 - val_loss: 1.5488 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5995 - binary_accuracy: 0.0000e+00 - val_loss: 1.5437 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5966 - binary_accuracy: 0.0000e+00 - val_loss: 1.5375 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5940 - binary_accuracy: 0.0000e+00 - val_loss: 1.5318 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5915 - binary_accuracy: 0.0000e+00 - val_loss: 1.5264 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5892 - binary_accuracy: 0.0000e+00 - val_loss: 1.5206 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5870 - binary_accuracy: 0.0000e+00 - val_loss: 1.5159 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5850 - binary_accuracy: 0.0000e+00 - val_loss: 1.5119 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5831 - binary_accuracy: 0.0000e+00 - val_loss: 1.5079 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5813 - binary_accuracy: 0.0000e+00 - val_loss: 1.5044 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5795 - binary_accuracy: 0.0000e+00 - val_loss: 1.5012 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5779 - binary_accuracy: 0.0000e+00 - val_loss: 1.4979 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5763 - binary_accuracy: 0.0000e+00 - val_loss: 1.4945 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5747 - binary_accuracy: 0.0000e+00 - val_loss: 1.4912 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5732 - binary_accuracy: 0.0000e+00 - val_loss: 1.4879 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5718 - binary_accuracy: 0.0000e+00 - val_loss: 1.4851 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5704 - binary_accuracy: 0.0000e+00 - val_loss: 1.4820 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5690 - binary_accuracy: 0.0000e+00 - val_loss: 1.4788 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5678 - binary_accuracy: 0.0000e+00 - val_loss: 1.4756 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5665 - binary_accuracy: 0.0000e+00 - val_loss: 1.4724 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5654 - binary_accuracy: 0.0000e+00 - val_loss: 1.4698 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5642 - binary_accuracy: 0.0000e+00 - val_loss: 1.4664 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5631 - binary_accuracy: 0.0000e+00 - val_loss: 1.4634 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5620 - binary_accuracy: 0.0000e+00 - val_loss: 1.4605 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5610 - binary_accuracy: 0.0000e+00 - val_loss: 1.4571 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5600 - binary_accuracy: 0.0000e+00 - val_loss: 1.4536 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5591 - binary_accuracy: 0.0000e+00 - val_loss: 1.4504 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5582 - binary_accuracy: 0.0000e+00 - val_loss: 1.4471 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5573 - binary_accuracy: 0.0000e+00 - val_loss: 1.4439 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5565 - binary_accuracy: 0.0000e+00 - val_loss: 1.4410 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5557 - binary_accuracy: 0.0000e+00 - val_loss: 1.4381 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5549 - binary_accuracy: 0.0000e+00 - val_loss: 1.4351 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5541 - binary_accuracy: 0.0000e+00 - val_loss: 1.4323 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5534 - binary_accuracy: 0.0000e+00 - val_loss: 1.4299 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5526 - binary_accuracy: 0.0000e+00 - val_loss: 1.4273 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5519 - binary_accuracy: 0.0000e+00 - val_loss: 1.4248 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5512 - binary_accuracy: 0.0000e+00 - val_loss: 1.4226 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5505 - binary_accuracy: 0.0000e+00 - val_loss: 1.4200 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5498 - binary_accuracy: 0.0000e+00 - val_loss: 1.4176 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5492 - binary_accuracy: 0.0000e+00 - val_loss: 1.4152 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5485 - binary_accuracy: 0.0000e+00 - val_loss: 1.4131 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5479 - binary_accuracy: 0.0000e+00 - val_loss: 1.4113 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5473 - binary_accuracy: 0.0000e+00 - val_loss: 1.4097 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5467 - binary_accuracy: 0.0000e+00 - val_loss: 1.4080 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5461 - binary_accuracy: 0.0000e+00 - val_loss: 1.4062 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5456 - binary_accuracy: 0.0000e+00 - val_loss: 1.4047 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5450 - binary_accuracy: 0.0000e+00 - val_loss: 1.4032 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5445 - binary_accuracy: 0.0000e+00 - val_loss: 1.4021 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5440 - binary_accuracy: 0.0000e+00 - val_loss: 1.4009 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5435 - binary_accuracy: 0.0000e+00 - val_loss: 1.3994 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5430 - binary_accuracy: 0.0000e+00 - val_loss: 1.3979 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5425 - binary_accuracy: 0.0000e+00 - val_loss: 1.3966 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5420 - binary_accuracy: 0.0000e+00 - val_loss: 1.3953 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5416 - binary_accuracy: 0.0000e+00 - val_loss: 1.3942 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5411 - binary_accuracy: 0.0000e+00 - val_loss: 1.3933 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5407 - binary_accuracy: 0.0000e+00 - val_loss: 1.3919 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5402 - binary_accuracy: 0.0000e+00 - val_loss: 1.3908 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5398 - binary_accuracy: 0.0000e+00 - val_loss: 1.3897 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5394 - binary_accuracy: 0.0000e+00 - val_loss: 1.3885 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5389 - binary_accuracy: 0.0000e+00 - val_loss: 1.3876 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5385 - binary_accuracy: 0.0000e+00 - val_loss: 1.3864 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5381 - binary_accuracy: 0.0000e+00 - val_loss: 1.3855 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5377 - binary_accuracy: 0.0000e+00 - val_loss: 1.3844 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5373 - binary_accuracy: 0.0000e+00 - val_loss: 1.3835 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5369 - binary_accuracy: 0.0000e+00 - val_loss: 1.3826 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5365 - binary_accuracy: 0.0000e+00 - val_loss: 1.3816 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5361 - binary_accuracy: 0.0000e+00 - val_loss: 1.3808 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5357 - binary_accuracy: 0.0000e+00 - val_loss: 1.3800 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5353 - binary_accuracy: 0.0000e+00 - val_loss: 1.3791 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5349 - binary_accuracy: 0.0000e+00 - val_loss: 1.3782 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5345 - binary_accuracy: 0.0000e+00 - val_loss: 1.3771 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5341 - binary_accuracy: 0.0000e+00 - val_loss: 1.3764 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5337 - binary_accuracy: 0.0000e+00 - val_loss: 1.3755 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5333 - binary_accuracy: 0.0000e+00 - val_loss: 1.3747 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5329 - binary_accuracy: 0.0000e+00 - val_loss: 1.3741 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5325 - binary_accuracy: 0.0000e+00 - val_loss: 1.3731 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5322 - binary_accuracy: 0.0000e+00 - val_loss: 1.3724 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5318 - binary_accuracy: 0.0000e+00 - val_loss: 1.3711 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5314 - binary_accuracy: 0.0000e+00 - val_loss: 1.3705 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5310 - binary_accuracy: 0.0000e+00 - val_loss: 1.3696 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5307 - binary_accuracy: 0.0000e+00 - val_loss: 1.3689 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5303 - binary_accuracy: 0.0000e+00 - val_loss: 1.3682 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5300 - binary_accuracy: 0.0000e+00 - val_loss: 1.3674 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5297 - binary_accuracy: 0.0000e+00 - val_loss: 1.3666 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5293 - binary_accuracy: 0.0000e+00 - val_loss: 1.3661 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5290 - binary_accuracy: 0.0000e+00 - val_loss: 1.3655 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5287 - binary_accuracy: 0.0000e+00 - val_loss: 1.3649 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5284 - binary_accuracy: 0.0000e+00 - val_loss: 1.3642 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5280 - binary_accuracy: 0.0000e+00 - val_loss: 1.3639 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5277 - binary_accuracy: 0.0000e+00 - val_loss: 1.3634 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5274 - binary_accuracy: 0.0000e+00 - val_loss: 1.3629 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5271 - binary_accuracy: 0.0000e+00 - val_loss: 1.3623 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5268 - binary_accuracy: 0.0000e+00 - val_loss: 1.3616 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5265 - binary_accuracy: 0.0000e+00 - val_loss: 1.3610 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5262 - binary_accuracy: 0.0000e+00 - val_loss: 1.3605 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5259 - binary_accuracy: 0.0000e+00 - val_loss: 1.3596 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5256 - binary_accuracy: 0.0000e+00 - val_loss: 1.3589 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5254 - binary_accuracy: 0.0000e+00 - val_loss: 1.3581 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5251 - binary_accuracy: 0.0000e+00 - val_loss: 1.3574 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5248 - binary_accuracy: 0.0000e+00 - val_loss: 1.3566 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.5245 - binary_accuracy: 0.0000e+00 - val_loss: 1.3558 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5242 - binary_accuracy: 0.0000e+00 - val_loss: 1.3553 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5240 - binary_accuracy: 0.0000e+00 - val_loss: 1.3552 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5237 - binary_accuracy: 0.0000e+00 - val_loss: 1.3546 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5234 - binary_accuracy: 0.0000e+00 - val_loss: 1.3539 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5232 - binary_accuracy: 0.0000e+00 - val_loss: 1.3534 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5229 - binary_accuracy: 0.0000e+00 - val_loss: 1.3529 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5227 - binary_accuracy: 0.0000e+00 - val_loss: 1.3523 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5224 - binary_accuracy: 0.0000e+00 - val_loss: 1.3518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5222 - binary_accuracy: 0.0000e+00 - val_loss: 1.3514 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5219 - binary_accuracy: 0.0000e+00 - val_loss: 1.3510 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5217 - binary_accuracy: 0.0000e+00 - val_loss: 1.3506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5214 - binary_accuracy: 0.0000e+00 - val_loss: 1.3501 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5212 - binary_accuracy: 0.0000e+00 - val_loss: 1.3496 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5210 - binary_accuracy: 0.0000e+00 - val_loss: 1.3492 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5207 - binary_accuracy: 0.0000e+00 - val_loss: 1.3488 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5205 - binary_accuracy: 0.0000e+00 - val_loss: 1.3482 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5203 - binary_accuracy: 0.0000e+00 - val_loss: 1.3477 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5200 - binary_accuracy: 0.0000e+00 - val_loss: 1.3473 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5198 - binary_accuracy: 0.0000e+00 - val_loss: 1.3468 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5196 - binary_accuracy: 0.0000e+00 - val_loss: 1.3464 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5193 - binary_accuracy: 0.0000e+00 - val_loss: 1.3460 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5191 - binary_accuracy: 0.0000e+00 - val_loss: 1.3457 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5189 - binary_accuracy: 0.0000e+00 - val_loss: 1.3456 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5187 - binary_accuracy: 0.0000e+00 - val_loss: 1.3456 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5184 - binary_accuracy: 0.0000e+00 - val_loss: 1.3456 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5182 - binary_accuracy: 0.0000e+00 - val_loss: 1.3454 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5180 - binary_accuracy: 0.0000e+00 - val_loss: 1.3452 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5177 - binary_accuracy: 0.0000e+00 - val_loss: 1.3451 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5175 - binary_accuracy: 0.0000e+00 - val_loss: 1.3450 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5173 - binary_accuracy: 0.0000e+00 - val_loss: 1.3448 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5171 - binary_accuracy: 0.0000e+00 - val_loss: 1.3446 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5169 - binary_accuracy: 0.0000e+00 - val_loss: 1.3443 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5167 - binary_accuracy: 0.0000e+00 - val_loss: 1.3440 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5165 - binary_accuracy: 0.0000e+00 - val_loss: 1.3437 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5163 - binary_accuracy: 0.0000e+00 - val_loss: 1.3437 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5161 - binary_accuracy: 0.0000e+00 - val_loss: 1.3435 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5159 - binary_accuracy: 0.0000e+00 - val_loss: 1.3434 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5157 - binary_accuracy: 0.0000e+00 - val_loss: 1.3434 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5155 - binary_accuracy: 0.0000e+00 - val_loss: 1.3433 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5153 - binary_accuracy: 0.0000e+00 - val_loss: 1.3433 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5151 - binary_accuracy: 0.0000e+00 - val_loss: 1.3431 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5149 - binary_accuracy: 0.0000e+00 - val_loss: 1.3432 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5147 - binary_accuracy: 0.0000e+00 - val_loss: 1.3429 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5145 - binary_accuracy: 0.0000e+00 - val_loss: 1.3429 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5144 - binary_accuracy: 0.0000e+00 - val_loss: 1.3427 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5142 - binary_accuracy: 0.0000e+00 - val_loss: 1.3426 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5140 - binary_accuracy: 0.0000e+00 - val_loss: 1.3424 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5138 - binary_accuracy: 0.0000e+00 - val_loss: 1.3424 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5136 - binary_accuracy: 0.0000e+00 - val_loss: 1.3422 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5135 - binary_accuracy: 0.0000e+00 - val_loss: 1.3420 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5133 - binary_accuracy: 0.0000e+00 - val_loss: 1.3416 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5131 - binary_accuracy: 0.0000e+00 - val_loss: 1.3407 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5129 - binary_accuracy: 0.0000e+00 - val_loss: 1.3408 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5127 - binary_accuracy: 0.0000e+00 - val_loss: 1.3404 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5125 - binary_accuracy: 0.0000e+00 - val_loss: 1.3401 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5124 - binary_accuracy: 0.0000e+00 - val_loss: 1.3397 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5122 - binary_accuracy: 0.0000e+00 - val_loss: 1.3393 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5120 - binary_accuracy: 0.0000e+00 - val_loss: 1.3391 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5118 - binary_accuracy: 0.0000e+00 - val_loss: 1.3390 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5117 - binary_accuracy: 0.0000e+00 - val_loss: 1.3389 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5115 - binary_accuracy: 0.0000e+00 - val_loss: 1.3388 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "22261/22261 [==============================] - 0s 13us/step - loss: 0.5113 - binary_accuracy: 0.0000e+00 - val_loss: 1.3387 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 0.5112 - binary_accuracy: 0.0000e+00 - val_loss: 1.3387 - val_binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2d1b72748>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 64\n",
    "autoencoder.compile(optimizer='SGD',loss='mean_squared_error',metrics=['binary_accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"3_16_ft_model.h5\",verbose=0,save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',histogram_freq=0,write_graph=True,write_images=True)\n",
    "autoencoder.fit(scaled_X_train, scaled_X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    validation_data=(scaled_X_val, scaled_X_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(scaled_X_test)\n",
    "mse = np.mean(np.power(scaled_X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.9373484751818297\n",
      "MCC on test set :  0.7043154047916869\n",
      "Precision :  0.7\n",
      "Recall :  0.7812852311161218\n",
      "AUC :  0.8692757090832407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6653</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "row_0           \n",
       "0      6653  297\n",
       "1       194  693"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold = error_df.reconstruction_error.describe()['25%']\n",
    "threshold = 1.6\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "# conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "print(\"Accuracy on test set : \", accuracy_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"MCC on test set : \" , matthews_corrcoef( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Precision : \" , precision_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Recall : \" , recall_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"AUC : \" , roc_auc_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "pd.crosstab(error_df.true_class.values,np.array(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PCA with Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 2278 features\n",
      "EntitySet scattered to workers in 3.742 seconds\n",
      "Elapsed: 00:06 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 11/11 chunks\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "# columns.remove('Target')\n",
    "# columns.append('domain')\n",
    "df_min=df[columns]\n",
    "\n",
    "es = ft.EntitySet(id = 'malicious')\n",
    "es.entity_from_dataframe(entity_id = 'data', dataframe = df_min, index = 'domain')\n",
    "\n",
    "feature_matrix_sessions, features_defs = ft.dfs(entityset=es,target_entity=\"data\",\n",
    "                                                trans_primitives = ['add','divide','multiply'],n_jobs=-1,\n",
    "                                                verbose=1,max_depth=1)\n",
    "\n",
    "df.set_index(['domain'],drop=True,inplace=True)\n",
    "fs=pd.merge(feature_matrix_sessions,pd.DataFrame(df_sel.Target),left_index=True, right_index=True)\n",
    "fs.replace([np.inf],0,inplace=True)\n",
    "fs.fillna(value=0,inplace=True)\n",
    "fs=fs.reindex(df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(fs, test_size=0.2, random_state=0)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=0)\n",
    "X_train = X_train[X_train.Target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=X_train.drop(['Target'] , axis=1)\n",
    "y=X_train.Target.values\n",
    "feature_name = X.columns.tolist()\n",
    "X=np.nan_to_num(X)\n",
    "scaler=StandardScaler()\n",
    "scaled_X=scaler.fit_transform(X)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pca = PCA(random_state=0)\n",
    "pca.fit(scaled_X)\n",
    "plt.figure(1, figsize=(10, 8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_),'--o', linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Number of Components',size=14)\n",
    "plt.xticks(size=12)\n",
    "plt.xlim([0,200])\n",
    "plt.ylabel('% Explained Variance',size=14)\n",
    "plt.yticks(size=12)\n",
    "plt.title('% Variance Explained by Principal Components',size=14,y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained using 125 components is: 0.7921788462326089\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(n_components=125,whiten=True,random_state=0)\n",
    "X_pca_21=pca.fit_transform(scaled_X)\n",
    "print(\"Variance explained using 125 components is:\",sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.drop(['Target'],axis=1)\n",
    "X_val_pca = pca.transform(X_val) \n",
    "\n",
    "y_test = X_test['Target']\n",
    "X_test = X_test.drop(['Target'], axis=1)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_pca_21.shape[1]\n",
    "encoding_dim = 20\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22261 samples, validate on 6270 samples\n",
      "Epoch 1/200\n",
      "22261/22261 [==============================] - 0s 20us/step - loss: 1.0612 - binary_accuracy: 0.0000e+00 - val_loss: 867144148991.0201 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0551 - binary_accuracy: 0.0000e+00 - val_loss: 866881004722.9958 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0517 - binary_accuracy: 0.0000e+00 - val_loss: 867137192942.5250 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0493 - binary_accuracy: 0.0000e+00 - val_loss: 867404621858.2966 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0473 - binary_accuracy: 0.0000e+00 - val_loss: 867585780448.5615 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0457 - binary_accuracy: 0.0000e+00 - val_loss: 867697276308.3740 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0441 - binary_accuracy: 0.0000e+00 - val_loss: 867760134750.0708 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0428 - binary_accuracy: 0.0000e+00 - val_loss: 867680272871.0123 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0414 - binary_accuracy: 0.0000e+00 - val_loss: 867384531278.6373 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0402 - binary_accuracy: 0.0000e+00 - val_loss: 867114773482.1155 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0390 - binary_accuracy: 0.0000e+00 - val_loss: 866774414463.8776 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0379 - binary_accuracy: 0.0000e+00 - val_loss: 866568121692.3560 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "22261/22261 [==============================] - 0s 14us/step - loss: 1.0368 - binary_accuracy: 0.0000e+00 - val_loss: 866298555480.6814 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0357 - binary_accuracy: 0.0000e+00 - val_loss: 865963604501.2311 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0347 - binary_accuracy: 0.0000e+00 - val_loss: 865668332796.6520 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0337 - binary_accuracy: 0.0000e+00 - val_loss: 865263489928.2883 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0327 - binary_accuracy: 0.0000e+00 - val_loss: 864867393300.9863 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0317 - binary_accuracy: 0.0000e+00 - val_loss: 864435258743.9567 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0308 - binary_accuracy: 0.0000e+00 - val_loss: 864013158791.1451 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0298 - binary_accuracy: 0.0000e+00 - val_loss: 863601318018.8173 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0289 - binary_accuracy: 0.0000e+00 - val_loss: 863099415885.3308 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0280 - binary_accuracy: 0.0000e+00 - val_loss: 862565724713.4827 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0271 - binary_accuracy: 0.0000e+00 - val_loss: 862115523268.4708 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0263 - binary_accuracy: 0.0000e+00 - val_loss: 860924988236.1875 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0254 - binary_accuracy: 0.0000e+00 - val_loss: 860407159449.0284 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0246 - binary_accuracy: 0.0000e+00 - val_loss: 859853236065.2555 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0238 - binary_accuracy: 0.0000e+00 - val_loss: 858540337850.9984 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0230 - binary_accuracy: 0.0000e+00 - val_loss: 857867186302.7343 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0222 - binary_accuracy: 0.0000e+00 - val_loss: 857203242765.9636 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0214 - binary_accuracy: 0.0000e+00 - val_loss: 856473553761.7455 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0206 - binary_accuracy: 0.0000e+00 - val_loss: 855005067075.2051 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0199 - binary_accuracy: 0.0000e+00 - val_loss: 854317664342.8849 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0191 - binary_accuracy: 0.0000e+00 - val_loss: 853594658138.7228 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0184 - binary_accuracy: 0.0000e+00 - val_loss: 852929381097.7072 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0177 - binary_accuracy: 0.0000e+00 - val_loss: 851546803597.6780 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0170 - binary_accuracy: 0.0000e+00 - val_loss: 850910675747.6848 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0163 - binary_accuracy: 0.0000e+00 - val_loss: 850127655202.2150 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0156 - binary_accuracy: 0.0000e+00 - val_loss: 848811600357.3793 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0149 - binary_accuracy: 0.0000e+00 - val_loss: 847871314344.2986 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0142 - binary_accuracy: 0.0000e+00 - val_loss: 847012320516.3279 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0136 - binary_accuracy: 0.0000e+00 - val_loss: 846189052445.8871 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0129 - binary_accuracy: 0.0000e+00 - val_loss: 844664859348.8026 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0123 - binary_accuracy: 0.0000e+00 - val_loss: 843821633380.8485 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0117 - binary_accuracy: 0.0000e+00 - val_loss: 842888991870.2444 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0111 - binary_accuracy: 0.0000e+00 - val_loss: 841350379303.9312 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0105 - binary_accuracy: 0.0000e+00 - val_loss: 840447378533.0935 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0099 - binary_accuracy: 0.0000e+00 - val_loss: 839415533991.6451 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0093 - binary_accuracy: 0.0000e+00 - val_loss: 837691226750.2444 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0087 - binary_accuracy: 0.0000e+00 - val_loss: 836739162829.6166 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0082 - binary_accuracy: 0.0000e+00 - val_loss: 835839311336.3190 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0076 - binary_accuracy: 0.0000e+00 - val_loss: 834023934155.9834 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 1.0071 - binary_accuracy: 0.0000e+00 - val_loss: 833072278913.5923 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0065 - binary_accuracy: 0.0000e+00 - val_loss: 832139515022.7394 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0060 - binary_accuracy: 0.0000e+00 - val_loss: 829994105278.0198 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0055 - binary_accuracy: 0.0000e+00 - val_loss: 828792602735.5459 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0050 - binary_accuracy: 0.0000e+00 - val_loss: 827810041676.8408 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0045 - binary_accuracy: 0.0000e+00 - val_loss: 825706425731.0623 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0040 - binary_accuracy: 0.0000e+00 - val_loss: 824615363025.2913 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0035 - binary_accuracy: 0.0000e+00 - val_loss: 823508257732.5525 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0031 - binary_accuracy: 0.0000e+00 - val_loss: 821314056553.0947 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0026 - binary_accuracy: 0.0000e+00 - val_loss: 820150071236.7158 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0022 - binary_accuracy: 0.0000e+00 - val_loss: 818987674298.6718 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0017 - binary_accuracy: 0.0000e+00 - val_loss: 816835568476.1926 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0013 - binary_accuracy: 0.0000e+00 - val_loss: 815792557040.4849 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0009 - binary_accuracy: 0.0000e+00 - val_loss: 814692817657.0590 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0004 - binary_accuracy: 0.0000e+00 - val_loss: 812913623325.3154 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 1.0000 - binary_accuracy: 0.0000e+00 - val_loss: 810592712216.0077 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9996 - binary_accuracy: 0.0000e+00 - val_loss: 809445568254.4486 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9992 - binary_accuracy: 0.0000e+00 - val_loss: 808296946807.2217 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9989 - binary_accuracy: 0.0000e+00 - val_loss: 805680758863.8622 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9985 - binary_accuracy: 0.0000e+00 - val_loss: 804222423125.4150 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9981 - binary_accuracy: 0.0000e+00 - val_loss: 802895088893.4686 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9977 - binary_accuracy: 0.0000e+00 - val_loss: 800048764310.6603 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9974 - binary_accuracy: 0.0000e+00 - val_loss: 798803926607.0457 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9970 - binary_accuracy: 0.0000e+00 - val_loss: 797332693737.2173 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9967 - binary_accuracy: 0.0000e+00 - val_loss: 795827624011.4526 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9963 - binary_accuracy: 0.0000e+00 - val_loss: 792821866963.9043 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9960 - binary_accuracy: 0.0000e+00 - val_loss: 791604804671.8571 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9957 - binary_accuracy: 0.0000e+00 - val_loss: 790100180638.0912 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9953 - binary_accuracy: 0.0000e+00 - val_loss: 786720849899.5853 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9950 - binary_accuracy: 0.0000e+00 - val_loss: 785504926247.5228 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9947 - binary_accuracy: 0.0000e+00 - val_loss: 783848329172.7209 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9944 - binary_accuracy: 0.0000e+00 - val_loss: 782062444321.7251 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9941 - binary_accuracy: 0.0000e+00 - val_loss: 778636955954.5468 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9938 - binary_accuracy: 0.0000e+00 - val_loss: 776977984739.1744 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9935 - binary_accuracy: 0.0000e+00 - val_loss: 775590597235.1389 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9932 - binary_accuracy: 0.0000e+00 - val_loss: 774018110652.7949 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9929 - binary_accuracy: 0.0000e+00 - val_loss: 772011732731.9988 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9926 - binary_accuracy: 0.0000e+00 - val_loss: 770210307556.7260 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9924 - binary_accuracy: 0.0000e+00 - val_loss: 767802374614.0275 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9921 - binary_accuracy: 0.0000e+00 - val_loss: 765942468542.1831 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9918 - binary_accuracy: 0.0000e+00 - val_loss: 764518787078.6960 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9916 - binary_accuracy: 0.0000e+00 - val_loss: 762304155730.4752 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9913 - binary_accuracy: 0.0000e+00 - val_loss: 761135712905.5131 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9911 - binary_accuracy: 0.0000e+00 - val_loss: 759366398055.5432 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9908 - binary_accuracy: 0.0000e+00 - val_loss: 756482699467.8201 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9906 - binary_accuracy: 0.0000e+00 - val_loss: 755215423417.2836 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9903 - binary_accuracy: 0.0000e+00 - val_loss: 753702995371.0748 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9901 - binary_accuracy: 0.0000e+00 - val_loss: 751947440965.3282 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9899 - binary_accuracy: 0.0000e+00 - val_loss: 750575529279.6121 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9896 - binary_accuracy: 0.0000e+00 - val_loss: 748867924841.2581 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9894 - binary_accuracy: 0.0000e+00 - val_loss: 747437074722.7048 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9892 - binary_accuracy: 0.0000e+00 - val_loss: 745750316067.6031 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9890 - binary_accuracy: 0.0000e+00 - val_loss: 743829721238.5786 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9888 - binary_accuracy: 0.0000e+00 - val_loss: 742805356457.1151 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9886 - binary_accuracy: 0.0000e+00 - val_loss: 740990854095.4948 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9883 - binary_accuracy: 0.0000e+00 - val_loss: 740097575061.7621 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9881 - binary_accuracy: 0.0000e+00 - val_loss: 738535548274.4037 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9879 - binary_accuracy: 0.0000e+00 - val_loss: 737352058774.1703 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9877 - binary_accuracy: 0.0000e+00 - val_loss: 735795252396.4631 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9875 - binary_accuracy: 0.0000e+00 - val_loss: 734716434851.2357 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9873 - binary_accuracy: 0.0000e+00 - val_loss: 733270803216.9033 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9871 - binary_accuracy: 0.0000e+00 - val_loss: 732125185231.4131 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9870 - binary_accuracy: 0.0000e+00 - val_loss: 730777989428.0166 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9868 - binary_accuracy: 0.0000e+00 - val_loss: 729734218871.5483 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9866 - binary_accuracy: 0.0000e+00 - val_loss: 728552041300.1901 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9864 - binary_accuracy: 0.0000e+00 - val_loss: 727641165885.4072 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9862 - binary_accuracy: 0.0000e+00 - val_loss: 726408820278.8748 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9860 - binary_accuracy: 0.0000e+00 - val_loss: 725351307259.9171 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9859 - binary_accuracy: 0.0000e+00 - val_loss: 724361451356.6826 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9857 - binary_accuracy: 0.0000e+00 - val_loss: 723326281132.5448 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9855 - binary_accuracy: 0.0000e+00 - val_loss: 722360935240.9213 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9853 - binary_accuracy: 0.0000e+00 - val_loss: 721369849035.9834 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9852 - binary_accuracy: 0.0000e+00 - val_loss: 720657670587.0801 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9850 - binary_accuracy: 0.0000e+00 - val_loss: 720050337722.2634 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9848 - binary_accuracy: 0.0000e+00 - val_loss: 719485979509.3435 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9847 - binary_accuracy: 0.0000e+00 - val_loss: 718934737270.9767 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.9845 - binary_accuracy: 0.0000e+00 - val_loss: 718053909068.5958 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9843 - binary_accuracy: 0.0000e+00 - val_loss: 717316594683.5905 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9842 - binary_accuracy: 0.0000e+00 - val_loss: 716796087403.2996 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9840 - binary_accuracy: 0.0000e+00 - val_loss: 716009498839.7423 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9838 - binary_accuracy: 0.0000e+00 - val_loss: 715573145416.9213 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9837 - binary_accuracy: 0.0000e+00 - val_loss: 715213213980.4990 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9835 - binary_accuracy: 0.0000e+00 - val_loss: 714583767598.3821 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9833 - binary_accuracy: 0.0000e+00 - val_loss: 714492931282.5161 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9832 - binary_accuracy: 0.0000e+00 - val_loss: 713501250493.8564 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9830 - binary_accuracy: 0.0000e+00 - val_loss: 713469823684.6342 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9829 - binary_accuracy: 0.0000e+00 - val_loss: 713163578674.8734 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9827 - binary_accuracy: 0.0000e+00 - val_loss: 712584087429.5120 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9825 - binary_accuracy: 0.0000e+00 - val_loss: 712502683734.5582 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9824 - binary_accuracy: 0.0000e+00 - val_loss: 711868628393.9318 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9822 - binary_accuracy: 0.0000e+00 - val_loss: 711918879768.0077 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9820 - binary_accuracy: 0.0000e+00 - val_loss: 711852059894.9359 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9819 - binary_accuracy: 0.0000e+00 - val_loss: 711723699265.1638 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9817 - binary_accuracy: 0.0000e+00 - val_loss: 711275894089.5745 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9816 - binary_accuracy: 0.0000e+00 - val_loss: 710805245895.3289 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9814 - binary_accuracy: 0.0000e+00 - val_loss: 710443050270.2954 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9812 - binary_accuracy: 0.0000e+00 - val_loss: 710388223205.7876 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9811 - binary_accuracy: 0.0000e+00 - val_loss: 710258053825.0411 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9809 - binary_accuracy: 0.0000e+00 - val_loss: 709780171325.4072 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9808 - binary_accuracy: 0.0000e+00 - val_loss: 708939222807.1094 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9806 - binary_accuracy: 0.0000e+00 - val_loss: 708531988112.8627 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9804 - binary_accuracy: 0.0000e+00 - val_loss: 708821565302.6500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9803 - binary_accuracy: 0.0000e+00 - val_loss: 707946918018.8173 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9801 - binary_accuracy: 0.0000e+00 - val_loss: 707617960712.5743 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9799 - binary_accuracy: 0.0000e+00 - val_loss: 707640255204.9709 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9798 - binary_accuracy: 0.0000e+00 - val_loss: 707941217601.4086 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9796 - binary_accuracy: 0.0000e+00 - val_loss: 707080818765.9025 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9795 - binary_accuracy: 0.0000e+00 - val_loss: 706880703809.2452 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9793 - binary_accuracy: 0.0000e+00 - val_loss: 706454212867.6747 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9791 - binary_accuracy: 0.0000e+00 - val_loss: 706342398667.9834 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9790 - binary_accuracy: 0.0000e+00 - val_loss: 706479632401.1483 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9788 - binary_accuracy: 0.0000e+00 - val_loss: 706714593192.9518 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9786 - binary_accuracy: 0.0000e+00 - val_loss: 707102855875.0010 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9785 - binary_accuracy: 0.0000e+00 - val_loss: 706108241226.0645 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9783 - binary_accuracy: 0.0000e+00 - val_loss: 707031660947.5573 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9782 - binary_accuracy: 0.0000e+00 - val_loss: 705682030756.9506 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9780 - binary_accuracy: 0.0000e+00 - val_loss: 706050707728.5767 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9779 - binary_accuracy: 0.0000e+00 - val_loss: 705802427078.9205 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9777 - binary_accuracy: 0.0000e+00 - val_loss: 705207731003.3658 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9775 - binary_accuracy: 0.0000e+00 - val_loss: 706208062021.5732 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9773 - binary_accuracy: 0.0000e+00 - val_loss: 705666768392.8191 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9772 - binary_accuracy: 0.0000e+00 - val_loss: 706631707296.3777 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9770 - binary_accuracy: 0.0000e+00 - val_loss: 705193749584.5155 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9768 - binary_accuracy: 0.0000e+00 - val_loss: 706620325970.3120 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9767 - binary_accuracy: 0.0000e+00 - val_loss: 705663118102.4562 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9765 - binary_accuracy: 0.0000e+00 - val_loss: 706381226633.3500 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9763 - binary_accuracy: 0.0000e+00 - val_loss: 706394690927.3007 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9761 - binary_accuracy: 0.0000e+00 - val_loss: 706226242110.5505 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "22261/22261 [==============================] - 0s 17us/step - loss: 0.9760 - binary_accuracy: 0.0000e+00 - val_loss: 705838746477.5043 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9758 - binary_accuracy: 0.0000e+00 - val_loss: 706548859682.2150 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9756 - binary_accuracy: 0.0000e+00 - val_loss: 705302888186.3656 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9754 - binary_accuracy: 0.0000e+00 - val_loss: 706131267134.8772 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9753 - binary_accuracy: 0.0000e+00 - val_loss: 706578757255.7168 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9751 - binary_accuracy: 0.0000e+00 - val_loss: 706028406954.9932 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9749 - binary_accuracy: 0.0000e+00 - val_loss: 705726565431.0381 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9747 - binary_accuracy: 0.0000e+00 - val_loss: 706545674687.9796 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9745 - binary_accuracy: 0.0000e+00 - val_loss: 705550062617.6409 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9743 - binary_accuracy: 0.0000e+00 - val_loss: 706108250206.8873 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9741 - binary_accuracy: 0.0000e+00 - val_loss: 706076145344.3879 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9739 - binary_accuracy: 0.0000e+00 - val_loss: 706147690194.5161 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9738 - binary_accuracy: 0.0000e+00 - val_loss: 707323432432.6482 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9736 - binary_accuracy: 0.0000e+00 - val_loss: 705837835055.1171 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9734 - binary_accuracy: 0.0000e+00 - val_loss: 706289242104.4874 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "22261/22261 [==============================] - 0s 15us/step - loss: 0.9732 - binary_accuracy: 0.0000e+00 - val_loss: 705406962462.9486 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9730 - binary_accuracy: 0.0000e+00 - val_loss: 705801328858.6820 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9728 - binary_accuracy: 0.0000e+00 - val_loss: 706264568771.0826 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9726 - binary_accuracy: 0.0000e+00 - val_loss: 706749208596.4147 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9724 - binary_accuracy: 0.0000e+00 - val_loss: 706842782656.1429 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "22261/22261 [==============================] - 0s 16us/step - loss: 0.9723 - binary_accuracy: 0.0000e+00 - val_loss: 706900381047.9567 - val_binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2d05f1c88>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 64\n",
    "autoencoder.compile(optimizer='SGD',loss='mean_squared_error',metrics=['binary_accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"3_16_pca_model.h5\",verbose=0,save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',histogram_freq=0,write_graph=True,write_images=True)\n",
    "autoencoder.fit(X_pca_21, X_pca_21,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    validation_data=(X_val_pca, X_val_pca),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set :  0.8427969886436136\n",
      "MCC on test set :  0.533700159416642\n",
      "Precision :  0.41010943199583116\n",
      "Recall :  0.887260428410372\n",
      "AUC :  0.8621913652843227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5818</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0     1\n",
       "row_0            \n",
       "0      5818  1132\n",
       "1       100   787"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test_pca)\n",
    "mse = np.mean(np.power(X_test_pca - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test})\n",
    "\n",
    "# threshold = error_df.reconstruction_error.describe()['25%']\n",
    "threshold = 900\n",
    "y_pred = [0 if e > threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "# conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "print(\"Accuracy on test set : \", accuracy_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"MCC on test set : \" , matthews_corrcoef( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Precision : \" , precision_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"Recall : \" , recall_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "print(\"AUC : \" , roc_auc_score( error_df.true_class.values , np.array(y_pred) ) )\n",
    "pd.crosstab(error_df.true_class.values,np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "To toggle code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Darshan Bhansali\n",
    "### HTML code to hide the input cells \n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "To toggle code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
